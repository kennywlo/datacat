[1mdiff --git a/client/python/examples/crawler.py b/client/python/examples/crawler.py[m
[1mindex 3172546..a024dee 100644[m
[1m--- a/client/python/examples/crawler.py[m
[1m+++ b/client/python/examples/crawler.py[m
[36m@@ -48,8 +48,10 @@[m [mclass Crawler:[m
             # Handle error here, or raise exception/error[m
             pass[m
         cksum_out = cksum_proc.stdout.read().split(b" ")[m
[31m-        cksum = cksum_out[0][m
[31m-        return cksum[m
[32m+[m[32m        # 0: checksum 1: size[m
[32m+[m[32m        cksum = cksum_out[0].decode("UTF-8")[m
[32m+[m[32m        ck = str(hex(int(cksum))).strip("0x")[m
[32m+[m[32m        return ck[m
 [m
     def get_metadata(self, dataset, dataset_location):[m
         """[m
[36m@@ -69,15 +71,11 @@[m [mclass Crawler:[m
         sys.stdout.write(f"Checking for new datasets at {datetime.now().ctime()}\n")[m
         try:[m
             if self.args.debug_mode:[m
[31m-                results = self.client.search([m
[31m-                    target="testpath/testfolder", version="current", site=WATCH_SITE,[m
[31m-                    query="scanStatus = 'UNSCANNED' or scanStatus = 'MISSING'", max_num=1000[m
[31m-                )[m
[32m+[m[32m                use_watch_folder = "testpath"[m
             else:[m
[31m-                results = self.client.search([m
[31m-                    WATCH_FOLDER + "/**", version="current", site=WATCH_SITE,[m
[31m-                    query="scanStatus = 'UNSCANNED' or scanStatus = 'MISSING'", max_num=1000[m
[31m-                )[m
[32m+[m[32m                use_watch_folder = WATCH_FOLDER[m
[32m+[m[32m            results = self.client.search(use_watch_folder + "/**", version="current", site=WATCH_SITE,[m
[32m+[m[32m                                         query="scanStatus = 'UNSCANNED' or scanStatus = 'MISSING'", max_num=1000)[m
         except DcException as error:[m
             sys.stderr.write(str(error))[m
             return False[m
[36m@@ -102,7 +100,7 @@[m [mclass Crawler:[m
                 # we tie the metadata to versionMetadata[m
                 scan_result = {[m
                     "size": stat.st_size,[m
[31m-                    "checksum": str(hex(int(cksum))).lstrip("0x"),[m
[32m+[m[32m                    "checksum": cksum,[m
                     # UTC datetime in ISO format (Note: We need Z to denote UTC Time Zone)[m
                     "locationScanned": datetime.utcnow().isoformat()+"Z",[m
                     "scanStatus": "OK"[m
